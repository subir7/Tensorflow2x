{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWtscN-ykkkC",
        "outputId": "079a3ebe-812f-47ee-ae79-3fd369b971aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as k\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#Load capsnet files\n",
        "from capsnet import losses\n",
        "from models import get_model"
      ],
      "metadata": {
        "id": "CVavAok6VnxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVlAogqIeIGH"
      },
      "outputs": [],
      "source": [
        "# Cifar10 64x64 dataset could be downloaded from below given kaggle link\n",
        "# https://www.kaggle.com/datasets/joaopauloschuler/cifar10-64x64-resized-via-cai-super-resolution\n",
        "\n",
        "!unzip /content/gdrive/MyDrive/MSCOCO/cifar10-64x64.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykrhAwJ7pjRT"
      },
      "outputs": [],
      "source": [
        "#https://raw.githubusercontent.com/MartinThoma/algorithms/master/ML/confusion-matrix/labels/cifar-100-labels.json\n",
        "\n",
        "'''\n",
        "CATEGORIES = ['class0','class1','class2','class3','class4','class5','class6','class7','class8','class9','class10',\n",
        "              'class11','class12','class13','class14','class15','class16','class17','class18','class19','class20',\n",
        "              'class21','class22','class23','class24','class25','class26','class27','class28','class29','class30',\n",
        "              'class31','class32','class33','class34','class35','class36','class37','class38','class39','class40',\n",
        "              'class41','class42','class43','class44','class45','class46','class47','class48','class49','class50',\n",
        "              'class51','class52','class53','class54','class55','class56','class57','class58','class59','class60',\n",
        "              'class61','class62','class63','class64','class65','class66','class67','class68','class69','class70',\n",
        "              'class71','class72','class73','class74','class75','class76','class77','class78','class79','class80',\n",
        "              'class81','class82','class83','class84','class85','class86','class87','class88','class89','class90',\n",
        "              'class91','class92','class93','class94','class95','class96','class97','class98','class99']'''\n",
        "\n",
        "#Cifar10 dataset has only 10 classes\n",
        "CATEGORIES = ['class0','class1','class2','class3','class4','class5','class6','class7','class8','class9']              \n",
        "SIZE = 64\n",
        "\n",
        "# Directory for loading TRAIN/TEST raw images \n",
        "DATA_DIR = \"/content/cifar10-64/test/\"\n",
        "SAVES_DIR = \"/\"\n",
        "\n",
        "\n",
        "training_data = []\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    category_path = os.path.join(DATA_DIR, category)\n",
        "    for image_path in os.listdir(category_path):\n",
        "        try:\n",
        "            img_path = os.path.join(category_path, image_path)\n",
        "            img_array = cv2.resize(cv2.imread(img_path, cv2.IMREAD_GRAYSCALE), (SIZE, SIZE))\n",
        "            class_index = CATEGORIES.index(category)\n",
        "            training_data.append([img_array, class_index])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for image, label in training_data:\n",
        "    images.append(image)\n",
        "    labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDslI6vetMRI"
      },
      "outputs": [],
      "source": [
        "#Save train images\n",
        "pickle_train_img = open(\"train_cifar10_64_images.pickle\",\"wb\")\n",
        "pickle.dump(images, pickle_train_img)\n",
        "pickle_train_img.close()\n",
        "\n",
        "#Save train labels\n",
        "pickle_train_label = open(\"train_cifar10_64_labels.pickle\",\"wb\")\n",
        "pickle.dump(labels, pickle_train_label)\n",
        "pickle_train_label.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDsZv32S8rmT"
      },
      "outputs": [],
      "source": [
        "#Save test images\n",
        "pickle_test_img = open(\"test_cifar10_64_images.pickle\",\"wb\")\n",
        "pickle.dump(images, pickle_test_img)\n",
        "pickle_test_img.close()\n",
        "\n",
        "#Save test labels\n",
        "pickle_test_label = open(\"test_cifar10_64_labels.pickle\",\"wb\")\n",
        "pickle.dump(labels, pickle_test_label)\n",
        "pickle_test_label.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yGyd8Zy1heF"
      },
      "outputs": [],
      "source": [
        "#Load train and test images, labels\n",
        "\n",
        "x_train_pickle = open(\"/content/train_cifar10_64_images.pickle\",\"rb\")\n",
        "x_train = pickle.load(x_train_pickle)\n",
        "\n",
        "y_train_pickle = open(\"/content/train_cifar10_64_labels.pickle\",\"rb\")\n",
        "y_train = pickle.load(y_train_pickle)\n",
        "\n",
        "x_test_pickle = open(\"/content/test_cifar10_64_images.pickle\",\"rb\")\n",
        "x_test = pickle.load(x_test_pickle)\n",
        "\n",
        "y_test_pickle = open(\"/content/test_cifar10_64_labels.pickle\",\"rb\")\n",
        "y_test = pickle.load(y_test_pickle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OoI4IGgxSUu",
        "outputId": "84c55214-3730-4c98-9e24-957f49503c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train images : 50000 : \n",
            "Total test images : 10000 : \n",
            "(50000, 64, 64, 1)\n",
            "(10000, 64, 64, 1)\n",
            "(50000,)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "x_train = np.array(x_train).reshape(-1, 64, 64, 1).astype(np.float32)\n",
        "x_test = np.array(x_test).reshape(-1, 64, 64, 1).astype(np.float32)\n",
        "\n",
        "y_train = np.array(y_train).astype(np.float32)\n",
        "y_test = np.array(y_test).astype(np.float32)\n",
        "\n",
        "print(\"Total train images : {} : \".format(len(x_train)))\n",
        "print(\"Total test images : {} : \".format(len(x_test)))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1NdoeDzxxhg"
      },
      "outputs": [],
      "source": [
        "#Scale images\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xgdK0eN6C9t",
        "outputId": "d81b236c-c375-46fc-e13d-56197f4e4904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "print(len(np.unique(y_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ71zAfs6L70",
        "outputId": "0fd52a2f-8f8a-4b3d-9306-d7c168424c1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 64, 64, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duMGw7MZ06Xn",
        "outputId": "3beb57f7-4c28-436d-e79a-45d000c7a9b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"original\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            " Layer (type)                                    Output Shape                     Param #           Connected to                                      \n",
            "======================================================================================================================================================\n",
            " input (InputLayer)                              [(None, 64, 64, 1)]              0                 []                                                \n",
            "                                                                                                                                                      \n",
            " conv (Conv2D)                                   (None, 56, 56, 256)              20992             ['input[0][0]']                                   \n",
            "                                                                                                                                                      \n",
            " conv_caps_2d (ConvCaps2D)                       (None, 24, 24, 32, 8)            166144            ['conv[0][0]']                                    \n",
            "                                                                                                                                                      \n",
            " lambda_4 (Lambda)                               (None, 24, 24, 32, 8)            0                 ['conv_caps_2d[0][0]']                            \n",
            "                                                                                                                                                      \n",
            " dense_caps (DenseCaps)                          (None, 10, 16)                   23592960          ['lambda_4[0][0]']                                \n",
            "                                                                                                                                                      \n",
            " lambda_5 (Lambda)                               (None, 10, 16)                   0                 ['dense_caps[0][0]']                              \n",
            "                                                                                                                                                      \n",
            " dc_masking (MaskCID)                            (None, 16)                       0                 ['lambda_5[0][0]']                                \n",
            "                                                                                                                                                      \n",
            " dc_dense_1 (Dense)                              (None, 512)                      8704              ['dc_masking[0][0]']                              \n",
            "                                                                                                                                                      \n",
            " dc_dense_2 (Dense)                              (None, 1024)                     525312            ['dc_dense_1[0][0]']                              \n",
            "                                                                                                                                                      \n",
            " dc_dense_3 (Dense)                              (None, 4096)                     4198400           ['dc_dense_2[0][0]']                              \n",
            "                                                                                                                                                      \n",
            " pred (Lambda)                                   (None, 10)                       0                 ['lambda_5[0][0]']                                \n",
            "                                                                                                                                                      \n",
            " recon (Reshape)                                 (None, 64, 64, 1)                0                 ['dc_dense_3[0][0]']                              \n",
            "                                                                                                                                                      \n",
            "======================================================================================================================================================\n",
            "Total params: 28,512,512\n",
            "Trainable params: 28,512,512\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "6250/6250 [==============================] - 811s 127ms/step - loss: 3.6454 - pred_loss: 3.6449 - recon_loss: 0.1039 - pred_acc: 0.1000 - val_loss: 3.6451 - val_pred_loss: 3.6449 - val_recon_loss: 0.0313 - val_pred_acc: 0.1000\n"
          ]
        }
      ],
      "source": [
        "BASE_PATH = \"\"\n",
        "\n",
        "ERR_FILE_NOT_FOUND = \"file not found\"\n",
        "\n",
        "\n",
        "def main(x_train, x_test, y_train, y_test) :\n",
        "    mode = \"train\"\n",
        "    model_name = \"original\"\n",
        "    dataset_name = \"cifar100\"\n",
        "\n",
        "    NUM_CLASSES = len(np.unique(y_train))\n",
        "\n",
        "    # configure model and print summary\n",
        "    model = get_model(name=model_name, input_shape=x_train.shape[1:], num_classes=NUM_CLASSES)\n",
        "    model.compile(optimizer=k.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0, clipvalue=0.5),\n",
        "                loss=[lambda a, b: losses.margin_loss(a, b, 0.9, 0.01), 'mse'],\n",
        "                loss_weights=[1, 5e-3],\n",
        "                metrics={'pred': 'acc'})\n",
        "    model.summary(line_length=150)\n",
        "\n",
        "    filepath = f\"{BASE_PATH}weights_{model_name}_{dataset_name}.hdf5\"\n",
        "\n",
        "    mode_name (model, mode, filepath)\n",
        "\n",
        "def mode_name (model, mode, filepath):\n",
        "    if mode == \"retrain\":\n",
        "        # TODO\n",
        "\n",
        "    if mode == \"train\" or mode == \"retrain\":\n",
        "        checkpoint = k.callbacks.ModelCheckpoint(filepath, save_best_only=True)\n",
        "        model.fit(x_train, [y_train, x_train],\n",
        "              batch_size=8,\n",
        "              epochs=1,\n",
        "              validation_data=(x_test, (y_test, x_test)),\n",
        "              callbacks=[checkpoint])\n",
        "\n",
        "    if mode == \"test\":\n",
        "        #TODO\n",
        "\n",
        "    if mode == \"demo\":\n",
        "        # TODO\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(x_train, x_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TODO LIST"
      ],
      "metadata": {
        "id": "vdrCB-6bLo6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Flickr dataset\n",
        "# Preprocess dataset\n",
        "# Extract feature using trained capsnet model weight\n",
        "# Train in transformer to generate captions\n",
        "\n",
        "# Calculate BELU score\n",
        "# Evaluation the performance"
      ],
      "metadata": {
        "id": "PIiidQUsLxTQ"
      },
      "execution_count": 2,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}